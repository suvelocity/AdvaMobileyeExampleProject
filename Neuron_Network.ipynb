{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in pairs and using the starter code -- train a neural network whose input is a cropped (81x81) color image and whose output is the probability that the center pixel of that image is part of a traffic light."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics to Discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "    Any combination of convolutional, fully-connected and pooling layers is possible as long as the output is the right size. Decreasing H and W can be done with pooling or changing the strides of the convolutions.\n",
    "## Learning Rate\n",
    "    Decreasing the learning rate over time can help\n",
    "## Loss\n",
    "    What is the appropriate loss for binary classification? (sigmoid cross entropy)\n",
    "## Overfitting\n",
    "    How can we tell if our net is overfitting? If the train set loss and test set loss diverge too much\n",
    "    What can we do about it? Regularization, Data Augmentation. There are also more advanced options like batchnorm and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "######## Imports ########\n",
    "#########################\n",
    "\n",
    "import numpy as np\n",
    "import os,sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#### Neural Net Class ###\n",
    "#########################\n",
    "class TLNet:\n",
    "\n",
    "    def __init__(self, out_dir, data_dir=None, crop_size=81):\n",
    "        \n",
    "        #########################\n",
    "        #### Initialize Net #####\n",
    "        #########################\n",
    "        \n",
    "        self.out_dir = out_dir\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        self.data_dir = data_dir\n",
    "        self.crop_size = crop_size\n",
    "        # Tensorflow placeholders serve as input pipes that we can fill later with data from any dataset we\n",
    "        # wish (as long as its examples are the expected shape)\n",
    "        self.input_data = tf.placeholder(tf.uint8, shape=[None, crop_size, crop_size, 3], name=\"input_imgs\")\n",
    "        self.labels = tf.placeholder(tf.uint8, [None, 1], name=\"labels\")\n",
    "\n",
    "        self.model_out = self.model(self.input_data)\n",
    "        \n",
    "        # We use a sigmoid on the model output so that it's predictions will be between 0 and 1\n",
    "        # representing the likelihood in percentage terms that the input image IS a positive example\n",
    "        self.prediction = tf.nn.sigmoid(self.model_out, name=\"prediction\")\n",
    "        \n",
    "        self.loss = self.calc_loss(self.model_out, tf.cast(self.labels, tf.float32))\n",
    "        \n",
    "        self.opt = None\n",
    "        \n",
    "        # Where to save the checkpoint\n",
    "        self.model_path = os.path.join(self.out_dir, \"TLNet.ckpt\")\n",
    "\n",
    "\n",
    "    def model(self, images):\n",
    "        \n",
    "        #########################\n",
    "        ##### Architecture ######\n",
    "        #########################\n",
    "        \n",
    "        # Cast uint8 images to float32 and normalize so their values are between 0 and 1\n",
    "        # Normalization is very important in training neural nets\n",
    "        images = tf.cast(images, tf.float32)\n",
    "        images *= (1. / 256)\n",
    "        \n",
    "        # Layers of the net\n",
    "        conv1 = self.conv_layer(images, 24, 'conv1', kernel=5, stride=1)\n",
    "        conv2 = self.conv_layer(conv1, 48, 'conv2', kernel=5, stride=2)\n",
    "        conv3 = self.conv_layer(conv2, 48, 'conv3', kernel=3, stride=1)\n",
    "        conv4 = self.conv_layer(conv3, 96, 'conv4', kernel=3, stride=2)\n",
    "        conv5 = self.conv_layer(conv4, 192, 'conv5', kernel=3, stride=1)\n",
    "        conv6 = self.conv_layer(conv5, 64, 'conv6', kernel=3, stride=2)\n",
    "        conv7 = self.conv_layer(conv6, 24, 'conv7', kernel=3, stride=1)\n",
    "#         conv4 = self.conv_layer(conv3, 48, 'conv4', kernel=3, stride=2)\n",
    "#         conv5 = self.conv_layer(conv4, 48, 'conv5', kernel=3, stride=1)\n",
    "#         conv6 = self.conv_layer(conv5, 96, 'conv6', kernel=3, stride=2)\n",
    "#         conv7 = self.conv_layer(conv6, 96, 'conv7', kernel=3, stride=1)\n",
    "#         conv8 = self.conv_layer(conv7, 192, 'conv8', kernel=3, stride=2)\n",
    "#         conv9 = self.conv_layer(conv8, 64, 'conv9', kernel=3, stride=1)\n",
    "#         conv10 = self.conv_layer(conv9, 24, 'conv10', kernel=3, stride=1)\n",
    "                \n",
    "        fc11 = self.fc_layer(conv7, output_neurons=48, name='fc11', doRelu=True)\n",
    "        fc12 = self.fc_layer(fc11, output_neurons=1, name='fc12', doRelu=False)\n",
    "    \n",
    "        output = tf.identity(fc12, name='output')\n",
    "\n",
    "        return output\n",
    "\n",
    "    def calc_loss(self, model_out, label):\n",
    "        \n",
    "        #########################\n",
    "        ######### Loss ##########\n",
    "        #########################\n",
    "        \n",
    "        # Sigmoid cross entropy is the go-to loss for yes/no classification tasks\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_out, labels=label))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def save(self, sess, model_path):\n",
    "        \n",
    "        # Save the current model\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        return save_path\n",
    "\n",
    "    def restore(self, sess, model_path):\n",
    "        \n",
    "        # Restore previously trained model\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "\n",
    "    def train(self, iters, learning_rate, batch_size, restore=False, ckpt_path=None):\n",
    "        \n",
    "        #########################\n",
    "        ####### Train Net #######\n",
    "        #########################\n",
    "        \n",
    "        # Prep data\n",
    "                \n",
    "        dataset_train = self.prep_data(os.path.join(self.data_dir, 'train', 'data.bin'), \n",
    "                                 os.path.join(self.data_dir, 'train', 'labels.bin'), \n",
    "                                 batch_size=batch_size, crop_size=self.crop_size)\n",
    "        dataset_val = self.prep_data(os.path.join(self.data_dir, 'val', 'data.bin'), \n",
    "                                os.path.join(self.data_dir, 'val', 'labels.bin'), \n",
    "                                batch_size=batch_size, crop_size=self.crop_size)\n",
    "\n",
    "        train_iterator = tf.data.Iterator.from_structure(dataset_train.output_types, dataset_train.output_shapes)\n",
    "        batch_of_train_images = train_iterator.get_next()\n",
    "        train_iterator = train_iterator.make_initializer(dataset_train)\n",
    "\n",
    "        val_iterator = tf.data.Iterator.from_structure(dataset_val.output_types, dataset_val.output_shapes)\n",
    "        batch_of_val_images = val_iterator.get_next()\n",
    "        val_iterator = val_iterator.make_initializer(dataset_val)\n",
    "        \n",
    "        if not self.opt:\n",
    "            \n",
    "            # Define optimizer\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Initialize variables and data iterators\n",
    "            sess.run(train_iterator)\n",
    "            sess.run(val_iterator)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            if restore:\n",
    "                # Restore trained weights and biases from checkpoint\n",
    "                self.restore(sess, ckpt_path)\n",
    "\n",
    "                print (\"Resuming from previously saved checkpoint ...\")\n",
    "                \n",
    "            # Define losses and accuracy\n",
    "            train_loss = 0.\n",
    "            val_loss = 0.\n",
    "            val_accuracy = 0.\n",
    "\n",
    "            # Train\n",
    "            for i in range(iters):\n",
    "\n",
    "                try:\n",
    "                    # Get a batch of images and labels from the training data generator\n",
    "                    train_batch = sess.run(batch_of_train_images)\n",
    "                    train_images = train_batch[0]\n",
    "                    train_labels = train_batch[1]\n",
    "                    \n",
    "                    # Run the optimizer (this is where the real training is occurring)\n",
    "                    _, out_loss = sess.run([self.opt, self.loss], feed_dict=\n",
    "                                           {self.input_data: train_images, self.labels: train_labels})\n",
    "                    \n",
    "                    # Update the loss average over all of training\n",
    "                    train_loss += np.mean(out_loss)\n",
    "\n",
    "                    if (i+1) % 10 == 0:\n",
    "                        # Print loss statement\n",
    "                        print (\"Iter: \" + str(i+1) + \", Current train loss: %f\" % (train_loss / (i+1)))\n",
    "\n",
    "                    if (i+1) % 100 == 0:\n",
    "                        # Save checkpoint\n",
    "                        print (\"Saving checkpoint\")\n",
    "                        save_path = self.save(sess, self.model_path)\n",
    "\n",
    "                    if (i+1) % 100 == 0:\n",
    "                        # Evaluate the net on the validation set\n",
    "                        print (\"Performing Evaluation\")\n",
    "                        \n",
    "                        val_batch = sess.run(batch_of_val_images)\n",
    "                        val_images = val_batch[0]\n",
    "                        val_labels = val_batch[1]\n",
    "\n",
    "                        out_prediction, out_val_loss = sess.run([self.prediction, self.loss],\n",
    "                                               feed_dict={self.input_data: val_images, self.labels: val_labels})\n",
    "                        \n",
    "                        val_loss += np.mean(out_val_loss)\n",
    "                        print (\"Current loss on val set: %f\" % (val_loss / ((i+1) / 100.)))\n",
    "                        \n",
    "                        val_accuracy += np.mean(np.round(out_prediction) == val_labels)\n",
    "                        print (\"Current accuracy on val set (percent of examples labeled correctly): \" + str(float(val_accuracy / ((i+1) / 100))))\n",
    "\n",
    "\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "\n",
    "            print (\"Model saved at \" + save_path)\n",
    "\n",
    "    def evaluate(self, ckpt_path, batch_size, crop_size=81):\n",
    "        \n",
    "        #########################\n",
    "        ## Evaluate Trained Net #\n",
    "        #########################\n",
    "                \n",
    "        dataset_val = self.prep_data(os.path.join(self.data_dir, 'val', 'data.bin'), os.path.join(self.data_dir, 'val', 'labels.bin'), batch_size=batch_size, crop_size=self.crop_size)\n",
    "\n",
    "        val_iterator = tf.data.Iterator.from_structure(dataset_val.output_types, dataset_val.output_shapes)\n",
    "\n",
    "        batch_of_images = val_iterator.get_next()\n",
    "\n",
    "        input_images_test = batch_of_images[0]\n",
    "        input_labels_test = batch_of_images[1]\n",
    "\n",
    "        val_iterator = val_iterator.make_initializer(dataset_val)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Initialize\n",
    "            sess.run(val_iterator)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            self.restore(sess, ckpt_path)\n",
    "\n",
    "            batch_out = sess.run(batch_of_images)\n",
    "            val_images = batch_out[0]\n",
    "            val_labels = batch_out[1]\n",
    "\n",
    "            print (\"resuming from previously saved checkpoint\")\n",
    "\n",
    "            predict_result, out_loss = sess.run([self.prediction, self.loss], feed_dict={self.input_data: val_images, self.labels: val_labels})\n",
    "\n",
    "            print (\"Loss on prediction was:\")\n",
    "            print (np.mean(out_loss))\n",
    "            print (\"Prediction was:\")\n",
    "            print (np.squeeze(predict_result))\n",
    "            print (\"Label was:\")\n",
    "            print (np.squeeze(val_labels))\n",
    "            print (\"Accuracy: %f\" % np.mean(np.round(predict_result) == val_labels))\n",
    "    \n",
    "    def predict(self, ckpt_path, img, crop_size=81):\n",
    "        \n",
    "        # FUNCTION\n",
    "        # Given an image and a checkpoint path, restore a trained model and run it on a single image\n",
    "\n",
    "        # INPUT\n",
    "        # **ckpt_path: filepath to model checkpoint\n",
    "        # **img: numpy array of shape (crop_size, crop_size, 3) and dtype uint8\n",
    "\n",
    "        # OUTPUT\n",
    "        # **prediction between 0 and 1 of how likely it is to be a traffic light\n",
    "\n",
    "        # Normalize the image, convert it to float32 and reshape it to be a single batch\n",
    "        \n",
    "        img = img.astype(np.float32) \n",
    "        img = img.reshape(1,crop_size,crop_size,3)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Initialize\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            self.restore(sess, ckpt_path)\n",
    "\n",
    "            print (\"resuming from previously saved checkpoint\")\n",
    "\n",
    "            # Run inference (note that the session does not need to be fed a label because\n",
    "            # we are not calculating the loss or running the optimizer)\n",
    "            predict_result = sess.run([self.prediction], feed_dict={self.input_data: img})\n",
    "\n",
    "            return float(np.squeeze(predict_result))\n",
    "\n",
    "    \n",
    "    #########################\n",
    "    ######## Layers #########\n",
    "    #########################\n",
    "    \n",
    "    def fc_layer(self, input_tensor, output_neurons, name, doRelu=True):\n",
    "        with tf.variable_scope(name):\n",
    "                          \n",
    "            shape = input_tensor.get_shape().as_list()\n",
    "            dim = 1\n",
    "            for d in shape[1:]:\n",
    "                dim *= d\n",
    "            x = tf.reshape(input_tensor, [-1, dim])\n",
    "                          \n",
    "            activation = None\n",
    "            if doRelu:\n",
    "                activation = tf.nn.relu\n",
    "            fc = tf.layers.dense(x, output_neurons, activation=activation)\n",
    "\n",
    "            return fc\n",
    "\n",
    "\n",
    "    def conv_layer(self, input_tensor, output_channels, name, kernel=3, stride=1, doRelu=True):\n",
    "        with tf.variable_scope(name):\n",
    "            strides = (stride,stride)\n",
    "            conv = tf.layers.conv2d(input_tensor, filters=output_channels, kernel_size=kernel, strides=strides, padding='SAME', data_format='channels_last', kernel_initializer=tf.keras.initializers.glorot_normal())\n",
    "\n",
    "            if doRelu:\n",
    "                conv = tf.nn.relu(conv)\n",
    "\n",
    "            return conv\n",
    "\n",
    "    def avg_pool(self, input_tensor, name, stride=2):\n",
    "        return tf.nn.avg_pool(input_tensor, ksize=[1, 2, 2, 1], strides=[1, stride, stride, 1], padding='SAME', name=name)\n",
    "\n",
    "    def max_pool(self, input_tensor, name, stride=2):\n",
    "        return tf.nn.max_pool(input_tensor, ksize=[1, 2, 2, 1], strides=[1, stride, stride, 1], padding='SAME', name=name)\n",
    "\n",
    "    #########################\n",
    "    ##### Import Data #######\n",
    "    #########################    \n",
    "\n",
    "    def prep_data(self, g_data, g_label, batch_size, crop_size=81):\n",
    "\n",
    "        # FUNCTION\n",
    "        # Given binary files, imports data as tensorflow dataset objects\n",
    "\n",
    "        # INPUT\n",
    "        # **g_data: filepath to binary data file\n",
    "        # **g_label: filepath to binary label file\n",
    "        # **batch_size: the number of examples the dataset will supply at each iteration\n",
    "        # **crop_size: size of the input image (assumed to be square)\n",
    "\n",
    "        # OUTPUT\n",
    "        # **tensorflow dataset object\n",
    "\n",
    "        filename_dataset = tf.data.Dataset.list_files(g_data)\n",
    "\n",
    "        image_dataset = filename_dataset.map(lambda x: tf.decode_raw(tf.read_file(x), tf.uint8))\n",
    "        image_dataset = image_dataset.map(lambda x: tf.reshape(x, [-1, crop_size, crop_size, 3]))\n",
    "        image_dataset = image_dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
    "        image_dataset = image_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "        filename_dataset = tf.data.Dataset.list_files(g_label)\n",
    "\n",
    "        label_dataset = filename_dataset.map(lambda x: tf.decode_raw(tf.read_file(x), tf.uint8))\n",
    "        label_dataset = label_dataset.map(lambda x: tf.reshape(x, [-1, 1]))\n",
    "        label_dataset = label_dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
    "        label_dataset = label_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "        full_dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "        full_dataset = full_dataset.prefetch(buffer_size=batch_size*5)\n",
    "        full_dataset = full_dataset.shuffle(buffer_size=batch_size*10)\n",
    "        full_dataset = full_dataset.repeat()\n",
    "\n",
    "        return full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a1564cd03fbc>:286: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-a1564cd03fbc>:278: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# data_dir = '/data_dir'\n",
    "# # out_dir = '/mobileye/algo_RP_8/jeff/wework/model'\n",
    "# out_dir = '/output'\n",
    "# ckpt_path = '/output/TLNet.ckpt'\n",
    "# model = TLNet(data_dir=data_dir, out_dir=out_dir, crop_size=81)\n",
    "#data_dir = r'C:\\Users\\user\\Documents\\excellenteam\\python\\mobilye project\\CityScapes\\data_dir2\\data_dir'\n",
    "data_dir = r'C:\\Users\\user\\Documents\\excellenteam\\python\\mobilye project\\CityScapes\\data_dir'\n",
    "# out_dir = '/mobileye/algo_RP_8/jeff/wework/model'\n",
    "out_dir = r'C:\\Users\\user\\Documents\\excellenteam\\python\\mobilye project\\CityScapes\\output'\n",
    "ckpt_path = r'C:\\Users\\user\\Documents\\excellenteam\\python\\mobilye project\\CityScapes\\output\\TLNet.ckpt'\n",
    "model = TLNet(data_dir=data_dir, out_dir=out_dir, crop_size=81)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\user\\Documents\\excellenteam\\python\\mobilye project\\CityScapes\\output\\TLNet.ckpt\n",
      "Resuming from previously saved checkpoint ...\n",
      "Iter: 10, Current train loss: 0.352834\n",
      "Iter: 20, Current train loss: 0.381905\n",
      "Iter: 30, Current train loss: 0.340439\n",
      "Iter: 40, Current train loss: 0.330340\n",
      "Iter: 50, Current train loss: 0.326598\n",
      "Iter: 60, Current train loss: 0.320910\n",
      "Iter: 70, Current train loss: 0.333539\n",
      "Iter: 80, Current train loss: 0.329114\n",
      "Iter: 90, Current train loss: 0.330361\n",
      "Iter: 100, Current train loss: 0.329500\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.401962\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8333333333333334\n",
      "Iter: 110, Current train loss: 0.326171\n",
      "Iter: 120, Current train loss: 0.323035\n",
      "Iter: 130, Current train loss: 0.324550\n",
      "Iter: 140, Current train loss: 0.324032\n",
      "Iter: 150, Current train loss: 0.317922\n",
      "Iter: 160, Current train loss: 0.319288\n",
      "Iter: 170, Current train loss: 0.320704\n",
      "Iter: 180, Current train loss: 0.322591\n",
      "Iter: 190, Current train loss: 0.324605\n",
      "Iter: 200, Current train loss: 0.327530\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.304466\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.875\n",
      "Iter: 210, Current train loss: 0.322954\n",
      "Iter: 220, Current train loss: 0.319098\n",
      "Iter: 230, Current train loss: 0.322078\n",
      "Iter: 240, Current train loss: 0.320993\n",
      "Iter: 250, Current train loss: 0.318994\n",
      "Iter: 260, Current train loss: 0.320128\n",
      "Iter: 270, Current train loss: 0.320571\n",
      "Iter: 280, Current train loss: 0.319830\n",
      "Iter: 290, Current train loss: 0.318524\n",
      "Iter: 300, Current train loss: 0.318247\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.381099\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8472222222222222\n",
      "Iter: 310, Current train loss: 0.319571\n",
      "Iter: 320, Current train loss: 0.319285\n",
      "Iter: 330, Current train loss: 0.320334\n",
      "Iter: 340, Current train loss: 0.319653\n",
      "Iter: 350, Current train loss: 0.320588\n",
      "Iter: 360, Current train loss: 0.320229\n",
      "Iter: 370, Current train loss: 0.320154\n",
      "Iter: 380, Current train loss: 0.319245\n",
      "Iter: 390, Current train loss: 0.321472\n",
      "Iter: 400, Current train loss: 0.322256\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.340384\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8541666666666666\n",
      "Iter: 410, Current train loss: 0.321268\n",
      "Iter: 420, Current train loss: 0.319480\n",
      "Iter: 430, Current train loss: 0.319513\n",
      "Iter: 440, Current train loss: 0.317974\n",
      "Iter: 450, Current train loss: 0.319408\n",
      "Iter: 460, Current train loss: 0.317757\n",
      "Iter: 470, Current train loss: 0.319200\n",
      "Iter: 480, Current train loss: 0.320708\n",
      "Iter: 490, Current train loss: 0.321386\n",
      "Iter: 500, Current train loss: 0.320642\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.340571\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8583333333333332\n",
      "Iter: 510, Current train loss: 0.319377\n",
      "Iter: 520, Current train loss: 0.318531\n",
      "Iter: 530, Current train loss: 0.318606\n",
      "Iter: 540, Current train loss: 0.319579\n",
      "Iter: 550, Current train loss: 0.320250\n",
      "Iter: 560, Current train loss: 0.321239\n",
      "Iter: 570, Current train loss: 0.319647\n",
      "Iter: 580, Current train loss: 0.320084\n",
      "Iter: 590, Current train loss: 0.319964\n",
      "Iter: 600, Current train loss: 0.319949\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.350957\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8402777777777777\n",
      "Iter: 610, Current train loss: 0.319954\n",
      "Iter: 620, Current train loss: 0.319391\n",
      "Iter: 630, Current train loss: 0.319188\n",
      "Iter: 640, Current train loss: 0.319227\n",
      "Iter: 650, Current train loss: 0.319200\n",
      "Iter: 660, Current train loss: 0.318542\n",
      "Iter: 670, Current train loss: 0.319372\n",
      "Iter: 680, Current train loss: 0.318637\n",
      "Iter: 690, Current train loss: 0.319241\n",
      "Iter: 700, Current train loss: 0.318468\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.321044\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8511904761904762\n",
      "Iter: 710, Current train loss: 0.318450\n",
      "Iter: 720, Current train loss: 0.318389\n",
      "Iter: 730, Current train loss: 0.317918\n",
      "Iter: 740, Current train loss: 0.317975\n",
      "Iter: 750, Current train loss: 0.318236\n",
      "Iter: 760, Current train loss: 0.317960\n",
      "Iter: 770, Current train loss: 0.317517\n",
      "Iter: 780, Current train loss: 0.317418\n",
      "Iter: 790, Current train loss: 0.317487\n",
      "Iter: 800, Current train loss: 0.317145\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.331035\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8385416666666666\n",
      "Iter: 810, Current train loss: 0.317072\n",
      "Iter: 820, Current train loss: 0.316485\n",
      "Iter: 830, Current train loss: 0.316139\n",
      "Iter: 840, Current train loss: 0.316761\n",
      "Iter: 850, Current train loss: 0.316772\n",
      "Iter: 860, Current train loss: 0.316119\n",
      "Iter: 870, Current train loss: 0.315509\n",
      "Iter: 880, Current train loss: 0.314790\n",
      "Iter: 890, Current train loss: 0.314708\n",
      "Iter: 900, Current train loss: 0.315040\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.317088\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8518518518518517\n",
      "Iter: 910, Current train loss: 0.315126\n",
      "Iter: 920, Current train loss: 0.314168\n",
      "Iter: 930, Current train loss: 0.313416\n",
      "Iter: 940, Current train loss: 0.312812\n",
      "Iter: 950, Current train loss: 0.311774\n",
      "Iter: 960, Current train loss: 0.310785\n",
      "Iter: 970, Current train loss: 0.310664\n",
      "Iter: 980, Current train loss: 0.310929\n",
      "Iter: 990, Current train loss: 0.310508\n",
      "Iter: 1000, Current train loss: 0.310906\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.302197\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8583333333333332\n",
      "Model saved at C:\\Users\\user\\Documents\\excellenteam\\python\\mobilye project\\CityScapes\\output\\TLNet.ckpt\n"
     ]
    }
   ],
   "source": [
    "model.train(1000, .0005, 24, restore=True, ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\user\\Documents\\excellenteam\\python\\mobilye project\\CityScapes\\output\\TLNet.ckpt\n",
      "resuming from previously saved checkpoint\n",
      "Loss on prediction was:\n",
      "0.23877008\n",
      "Prediction was:\n",
      "[0.02750662 0.98608875 0.20504054 0.987129   0.24548316 0.9880327\n",
      " 0.01797357 0.5455116  0.22006094 0.985988   0.07993221 0.94560665\n",
      " 0.0649167  0.9260913  0.30353558 0.87745774 0.11808205 0.88400817\n",
      " 0.04098651 0.662215   0.03501588 0.904411   0.881948   0.04266548\n",
      " 0.97755647 0.01062176 0.9978546  0.04155183 0.99783003 0.02298519\n",
      " 0.8476151  0.02817136 0.8997547  0.04182896 0.8353575  0.01419181\n",
      " 0.85414124 0.80009675 0.7652111  0.11613953 0.9159436  0.23157066\n",
      " 0.75122905 0.10232499 0.7323341  0.11585858 0.8546448  0.17998657\n",
      " 0.9570846  0.02465096 0.918594   0.00357413 0.81307024 0.00238776\n",
      " 0.4941048  0.00974327 0.96097785 0.01887777 0.9831852  0.22313616\n",
      " 0.5846457  0.34258634 0.9377273  0.01959509 0.3564608  0.9901755\n",
      " 0.02719066 0.35838968 0.10028541 0.8791306  0.97743285 0.0714961\n",
      " 0.9859983  0.16097152 0.9177661  0.8211156  0.9570347  0.36151278\n",
      " 0.27477494 0.12722781 0.20994392 0.03300914 0.60204566 0.09878558\n",
      " 0.80719256 0.08856606 0.2002702  0.12637907 0.64859694 0.17522258\n",
      " 0.8821728  0.05721378 0.14025089 0.08597299 0.82959485 0.28042638\n",
      " 0.94120437 0.15379415 0.879847   0.09515524]\n",
      "Label was:\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0]\n",
      "Accuracy: 0.920000\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(ckpt_path=ckpt_path, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\user\\Documents\\excellenteam\\python\\mobilye project\\CityScapes\\output\\TLNet.ckpt\n",
      "resuming from previously saved checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5755100250244141"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_image = np.zeros((81,81,3), dtype=np.uint8)\n",
    "model.predict(ckpt_path, fake_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
